{
  "category": "model",
  "description": "Deploy mainstream open-source models with a single click to enable private AI inference and fine-tuning, ensuring data privacy and local control.",
  "developer": {
    "avatar": "https://coco.infini.cloud/extensions/infinilabs/assets/avatar.png",
    "github_handle": "infinilabs",
    "id": "infinilabs",
    "location": "Internet",
    "name": "infinilabs",
    "website": "https://github.com/infinilabs"
  },
  "icon": "/assets/icons/llm/ollama.svg",
  "name": "Ollama",
  "platforms": [
    "macos",
    "linux",
    "windows"
  ],
  "screenshots": [
    {
      "title": "Ollama",
      "url": "/assets/screenshot.png"
    }
  ],
  "tags": [
   "model",
    "llm"
  ],
  "type": "llm-provider",
  "url": {
    "home": "http://coco.rs"
  },
  "version": {
    "number": "0.1"
  },
  "payload": {
    "id" : "ollama",
    "name" : "Ollama",
    "api_key" : "",
    "api_type" : "ollama",
    "base_url" : "http://127.0.0.1:11434",
    "icon" : "/assets/icons/llm/ollama.svg",
    "models" : [
      {"name":"qwen2.5:32b"},
      {"name":"deepseek-r1:32b"},
      {"name":"deepseek-r1:14b"},
      {"name":"deepseek-r1:8b"}
    ],
    "enabled" : false,
    "builtin" : true,
    "description": "Deploy mainstream open-source models with a single click to enable private AI inference and fine-tuning, ensuring data privacy and local control."
  }
}